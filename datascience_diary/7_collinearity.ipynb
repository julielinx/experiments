{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry 7 - Collinearity\n",
    "\n",
    "In <font color='red'>Entry 6</font> I looked at the correlation between the prediction features and the feature of interest (well, kinda. This problem question is a little weird in that I'll be predicting mass_1024kg, but am interested in how the other features relate to atmospheric_mass_kg). Now I'll look at how all of the features relate to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "[This Data Science Central blogger](https://www.datasciencecentral.com/profiles/blogs/multicollinearity-a-problem-or-an-opportunity) put it very sucintly: 'Collinearity is infamously famous for inflating the variance of at least one estimated regression coefficient, which can cause the model to predict erroneously.' Coefficients are also how models are intrepreted. Screwey coefficients can hinder understanding how a model is getting its results.\n",
    "\n",
    "- [Collinearity](https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/) occurs when two variables are corelated; a change in one causes changes in the other.\n",
    "- [Multiplecollinearity](https://etav.github.io/python/vif_factor_python.html) occurs when three or more variables are corelated. Multicollinearity presents a larger challenge because it can be present even when isolated pairs of variables are not collinear.\n",
    "\n",
    "Most models and statistical methods assume variables are independent. While having collinear features isn't always a problem, as discussed above it can cause issues in the coefficients, effecting predictions and making interpretability more difficult.\n",
    "\n",
    "Not every problem requires interpretability, but every problem shoots for the most accurate result. [This answer](https://stats.stackexchange.com/questions/168622/why-is-multicollinearity-not-checked-in-modern-statistics-machine-learning) on stats.stackexchange makes the argument that cross-validation (more on cross-validation in a later entry) negates the risk of a slight change in the data causing huge fluctuations in coefficients (the fluctuation causing less accurate predictions).\n",
    "\n",
    "That aside, the problems I address at work require interpretability. As such, in my case it's better to address collinearity than not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
