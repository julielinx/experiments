{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry 14 - Encoding Categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "Most machine learning algorithms require features to be numeric. Per usual, decision trees/random forests are the exception (the algorithm is just more forgiving in general). Last time I played with R, categorical variables were allowed to remain categorical for decision trees/random forests.\n",
    "\n",
    "My tool of choice, scikit-learn, [doesn't allow for categoricals](https://scikit-learn.org/stable/faq.html#why-do-categorical-variables-need-preprocessing-in-scikit-learn-compared-to-other-tools). All features must be encoded as numeric values. The reasons for this have to do with the [extensive amount of work](https://scikit-learn.org/stable/faq.html#why-does-scikit-learn-not-directly-work-with-for-example-pandas-dataframe) needed to support categorical types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Options\n",
    "\n",
    "- Scikit-learn's preprocessing module\n",
    "  - Binarizer\n",
    "  - LabelBinarizer\n",
    "  - LabelEncoder\n",
    "  - OneHotEncoder\n",
    "  - OrdinalEncoder\n",
    "  - label_binarize\n",
    "- Scikit-learn's feature_extractor module\n",
    "  - DictVectorizer\n",
    "  - FeatureHasher\n",
    "- category-encoders\n",
    "  - Backward Difference Contrast\n",
    "  - BaseN\n",
    "  - Binary\n",
    "  - Count\n",
    "  - Hashing\n",
    "  - Helmert Contrast\n",
    "  - James-Stein Estimator\n",
    "  - LeaveOneOut\n",
    "  - M-estimator\n",
    "  - Ordinal\n",
    "  - One-Hot\n",
    "  - Polynomial Contrast\n",
    "  - Sum Contrast\n",
    "  - Target Encoding\n",
    "  - Weight of Evidence\n",
    "- pandas\n",
    "  - .astype('category') method + .cat.codes method\n",
    "  - .get_dummies()\n",
    "  - .replace() method + dictionary mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Proposed Solution\n",
    "\n",
    "The **category-encoders** module appeals to me. Benefits include:\n",
    "- Fully compatible with scikit-learn's transformers (it can be included in pipelines)\n",
    "- First-class support for pandas dataframes as an input (and optionally as output)\n",
    "- Can explicitly configure which columns in the data are encoded by name or index, or infer non-numeric columns regardless of input type\n",
    "- Portability: train a transformer on data, pickle it, reuse it later and get the same thing out\n",
    "- All methods are imported in one library\n",
    "- Largest number of encoding options from the three module choices\n",
    "- The BaseN option allows for multiple encoding methods to allow encoding to become a tunable hyperparameter\n",
    "\n",
    "Compared with **Scikit-learn** where:\n",
    "- Each encoding method has to be imported by name from the preprocessing module\n",
    "- No explicit configuration of which columns to encode (it assumes all columns passed to it are categorical)\n",
    "\n",
    "The **pandas** options are rather limited - only three methods. They also seem to require more code than the other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
